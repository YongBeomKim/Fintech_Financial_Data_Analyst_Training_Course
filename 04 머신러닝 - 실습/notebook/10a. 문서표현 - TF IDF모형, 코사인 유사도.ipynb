{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #문서표현위함\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TF IDF representation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Create a TF IDF matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data.\n",
    "my_docs = [\"The economic slowdown is becoming more severe\",\n",
    "           \"The movie was simply awesome\",\n",
    "           \"I like cooking my own food\",\n",
    "           \"Samsung is announcing a new technology\",\n",
    "           \"Machine Learning is an example of awesome technology\",\n",
    "           \"All of us were excited at the movie\",\n",
    "           \"We have to do more to reverse the economic slowdown\"]\n",
    "\n",
    "#7개의 document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A very simple pre-processing.\n",
    "my_docs = [x.lower() for x in my_docs]\n",
    "\n",
    "#소문자해서 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer() arguments: <br>\n",
    "- *max_features* : maximum number of features (distict words). <br>\n",
    "- *min_df* : The minimum DF. Integer value means count and real number (0~1) means proportion. <br> \n",
    "- *max_df* : The maximum DF. Integer value means count and real number (0~1) means proportion. Helps to filter out the stop words. <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 10, min_df = 1, max_df = 3, stop_words = stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(my_docs).toarray()               # Conversion to a dense matrix with toarray().\n",
    "\n",
    "#vectorizer가 객체, TfidVectorizer는 클래스\n",
    "#TfidVectorizer의 인자값 max_features 최댓값 10: 단어가 10개 이상이어도 10개까지만 나오게\n",
    "#min_df,max_df: minimum document prequency(너무 작아도 안됨)\n",
    "#stopwords.words('english'): nrk가 제공하는 영문\n",
    "\n",
    "\n",
    "#fit_transform: 학습하면서 행렬로 변환까지함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the X matrix (m x n).\n",
    "X.shape \n",
    "\n",
    "#문서개수*feature개수  \n",
    "#문서 7개 feature 10개 (위에서 10개를 최대로 설정함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['announcing', 'awesome', 'economic', 'movie', 'reverse', 'samsung', 'severe', 'simply', 'slowdown', 'technology']\n"
     ]
    }
   ],
   "source": [
    "# Output the features.\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "#feature 이름들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.53828134 0.         0.         0.\n",
      " 0.64846464 0.         0.53828134 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Output a vector corresponding to a document.\n",
    "print(X[0]) #[0,:]도 넘피배열이라 같음\n",
    "\n",
    "#첫번째문서 보기(첫번째 행) \n",
    "#결과는 10개의 성분으로 이뤄진 하나의 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Calculate the cosine similarity: 코사인 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.579],\n",
       "       [0.   , 1.   , 0.   , 0.   , 0.381, 0.538, 0.   ],\n",
       "       [0.   , 0.   , 1.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 1.   , 0.358, 0.   , 0.   ],\n",
       "       [0.   , 0.381, 0.   , 0.358, 1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.538, 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "       [0.579, 0.   , 0.   , 0.   , 0.   , 0.   , 1.   ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The cosine similarity matrix.\n",
    "1 - np.round(pairwise_distances(X, metric=\"cosine\"),3)\n",
    "\n",
    "#코사인 유사도는 distance와 반대임\n",
    "#코사인 유사도는 클수록 좋음, 거리는 짧을수록 좋음: 그래서 1에서 빼줘야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5794936078209331"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity between two documents by linear algebra.\n",
    "np.dot(X[0], X[6].T)\n",
    "\n",
    "#첫번째 문서와 일곱번째 문서 간  dot 구해야함\n",
    "#그런데 둘다 행이니 dot 불가능 -> 행과 열로 만들어줘야 함\n",
    "\n",
    "#분모 구하기: 이미 길이가 1로 정규화 되어있어 분모가 둘 다 1임->나눠줄 필요 없음\n",
    "#분자 구하기: dot가지고 코사인 유사도 구하면 됨\n",
    "\n",
    "#1,2번째 문서는 유사성이 높은 편"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35793913951147677"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine similarity between two documents by linear algebra.\n",
    "np.dot(X[3], X[4].T)\n",
    "\n",
    "#3,4번째 문서는 유사성이 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
